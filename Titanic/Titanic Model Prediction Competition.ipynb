{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWyf-y9tgl71"
   },
   "source": [
    "Cleaning Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1732495245596,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "q9wm_YaFfvLx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "#df['Cabin'].isnull().sum()\n",
    "\n",
    "#df['Cabin']\n",
    "#Replace missing values with the most common value in the column (Cabin).\n",
    "df.fillna({'Cabin': df['Cabin'].mode()[0]}, inplace=True)\n",
    "\n",
    "#Replace missing values with the most common value in the column (Embarked).\n",
    "df.fillna({'Embarked': df['Embarked'].mode()[0]}, inplace=True)\n",
    "\n",
    "#Create a new column(Column_Age) & fill all the missing values with the mean mode\n",
    "df['Column_Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "#df['Column_Age'].count()\n",
    "\n",
    "#Add 'Column_Age to the data frame\n",
    "df['Age'] = df['Column_Age']\n",
    "\n",
    "#Drop the 'Age' column\n",
    "df = df.drop('Age', axis=1)\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "df.to_csv(\"cleaned_train_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xO7PvoHihvS"
   },
   "source": [
    "Encode Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1732495252345,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "J4gE6Y6gixj8"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_encode = pd.read_csv('cleaned_train_dataset.csv')\n",
    "train_encode = pd.DataFrame(train_encode)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_encode[['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']]\n",
    "y = train_encode['Survived']\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # `drop='first'` removes the first category to avoid multicollinearity\n",
    "\n",
    "# Fit and transform the features\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame and add column names\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n",
    "\n",
    "# Concatenate encoded features with target variable\n",
    "df_encoded = pd.concat([encoded_df, y], axis=1)\n",
    "\n",
    "#print(df_encoded)\n",
    "\n",
    "# Save the encoded dataframe to a CSV file\n",
    "df_encoded.to_csv(\"encoded_train_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTSEzUiUkCKV"
   },
   "source": [
    "Model Training (LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 455,
     "status": "ok",
     "timestamp": 1732493976172,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "NrH2jevmkHbe",
    "outputId": "5e1ebf14-34ba-4d43-8786-1c21625ac379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7932960893854749\n",
      "Confusion Matrix:\n",
      "[[86 19]\n",
      " [18 56]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       105\n",
      "           1       0.75      0.76      0.75        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.79      0.79       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_1']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "\n",
    "# Load and prepare data\n",
    "data = pd.read_csv('encoded_train_data.csv')\n",
    "\n",
    "# Specify the name of the target column\n",
    "target_column = 'Survived'  # Replace with your actual target column name\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=[target_column])  # Features (independent variables)\n",
    "y = data[target_column]  # Target (dependent variable)\n",
    "\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model with the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'model_1')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dBzFiFRhYtD"
   },
   "source": [
    "Cleaning Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1732495280693,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "NMrbuTslhef6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "\n",
    "#df['Cabin'].isnull().sum()\n",
    "\n",
    "#df['Cabin']\n",
    "#Replace missing values with the most common value in the column (Cabin).\n",
    "df.fillna({'Cabin': df['Cabin'].mode()[0]}, inplace=True)\n",
    "\n",
    "#Replace missing values with the most common value in the column (Embarked).\n",
    "df.fillna({'Embarked': df['Embarked'].mode()[0]}, inplace=True)\n",
    "\n",
    "#Fill the missing value in Fare with the mean\n",
    "df['Fare'] = df['Fare'].fillna(df['Fare'].mean())\n",
    "\n",
    "#Create a new column(Column_Age) & fill all the missing values with the mean mode\n",
    "df['Column_Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "#df['Column_Age'].count()\n",
    "\n",
    "#Add 'Column_Age to the data frame\n",
    "df['Age'] = df['Column_Age']\n",
    "\n",
    "#Drop the 'Age' column\n",
    "df = df.drop('Age', axis=1)\n",
    "df.isnull().sum()\n",
    "\n",
    "df.to_csv(\"cleaned_test_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScxEzugFkZ0d"
   },
   "source": [
    "Encode Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 1088,
     "status": "ok",
     "timestamp": 1732495762707,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "dZ88mjJKkfJi"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "train_encode = pd.read_csv('cleaned_test_dataset.csv')\n",
    "train_encode = pd.DataFrame(train_encode)\n",
    "\n",
    "# Separate features and target\n",
    "X = train_encode[['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']]\n",
    "y = train_encode['PassengerId']\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # `drop='first'` removes the first category to avoid multicollinearity\n",
    "\n",
    "# Fit and transform the features\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame and add column names\n",
    "encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n",
    "\n",
    "# Concatenate encoded features with target variable\n",
    "df_encoded = pd.concat([encoded_df, y], axis=1)\n",
    "\n",
    "#print(df_encoded)\n",
    "\n",
    "# Save the encoded dataframe to a CSV file\n",
    "df_encoded.to_csv(\"encoded_test_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjdQ3QBem9o8"
   },
   "source": [
    "Predict The Passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 394,
     "status": "ok",
     "timestamp": 1732495769727,
     "user": {
      "displayName": "Ned Palom",
      "userId": "06455553497609884633"
     },
     "user_tz": -600
    },
    "id": "Do6JL10pqeEu",
    "outputId": "ffd2a73d-1d24-4b16-c8a9-e30642a62d5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerID  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load('model_1')\n",
    "\n",
    "# Load the training data to get the original feature names\n",
    "training_data = pd.read_csv('encoded_train_data.csv')  # Replace with the path to your encoded training data\n",
    "training_features = training_data.drop(columns=['Survived']).columns  # Get the feature names from the training data\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('encoded_test_dataset.csv')\n",
    "\n",
    "# Specify the name of the target column (if it exists in test data, remove it)\n",
    "target_column = 'Survived' ,'Passengerid'  # Replace with your actual target column name, if needed\n",
    "\n",
    "# Remove the target column if it exists in test data\n",
    "if target_column in test_data.columns:\n",
    "    test_data = test_data.drop(columns=[target_column])\n",
    "\n",
    "# Reorder the columns in test_data to match the training data, filling missing columns with 0\n",
    "test_data = test_data.reindex(columns=training_features, fill_value=0)\n",
    "\n",
    "# Make predictions for each row in the test data\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Create an IndexID column with values from 0 to 417 (or len(predictions) - 1)\n",
    "index_ids = list(range(892, 1310))\n",
    "\n",
    "# Create a DataFrame with IndexID and Survived columns\n",
    "results = pd.DataFrame({\n",
    "    'PassengerID': index_ids,\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(results)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sm07gcnspqpi"
   },
   "source": [
    "# New Section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNMsCvpLrKhRZfOF7xCxUX4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
