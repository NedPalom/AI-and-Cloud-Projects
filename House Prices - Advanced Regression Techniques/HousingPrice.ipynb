{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN1KAhbEnPwNFHZQoeUV2NN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Predict Housing Price"],"metadata":{"id":"2XN51A8ZBhbe"}},{"cell_type":"markdown","source":["Preprocess Dataset Cleaning\n","1. Identify missing rows\n","2. Drop the missing rows\n","3. Identify duplate values\n","4. Drop Duplicate values"],"metadata":{"id":"j2oddwg3cP4O"}},{"cell_type":"code","execution_count":2,"metadata":{"collapsed":true,"id":"lNZVUvkAcMJu","executionInfo":{"status":"ok","timestamp":1731715944474,"user_tz":-600,"elapsed":513,"user":{"displayName":"Ned Palom","userId":"06455553497609884633"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"174110d1-2150-43db-fa09-17012febca9f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Outliers before imputation: 0       60.0\n","1       20.0\n","2       60.0\n","3       70.0\n","4       60.0\n","        ... \n","1455    60.0\n","1456    20.0\n","1457    70.0\n","1458    20.0\n","1459    20.0\n","Name: MSSubClass, Length: 1460, dtype: float64\n","Outliers after imputation: MSSubClass    10\n","dtype: int64\n"]}],"source":["import pandas as pd\n","from scipy import stats\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","#identify missing values\n","df = pd.read_csv('train.csv')\n","\n","# Load your dataset\n","df = pd.read_csv('train.csv')\n","#*********OUTLIERS*********************\n","# Select only the numerical columns\n","numerical_df = df.select_dtypes(include=[np.number])\n","\n","# Calculate the Z-scores for each numerical column\n","z_scores = np.abs(stats.zscore(numerical_df))\n","\n","# Set a threshold for identifying outliers\n","threshold = 3\n","\n","# Assuming you want to replace outliers based on z-score\n","# and replace them with median for the column\n","upper_limit = numerical_df['MSSubClass'].mean() + threshold * numerical_df['MSSubClass'].std()\n","median = numerical_df['MSSubClass'].median()\n","df['MSSubClass'] = df['MSSubClass'].apply(lambda x: median if x > upper_limit else x)\n","#print(df['MSSubClass'])\n","\n","# Recalculate the Z-scores after imputation\n","z_scores_post_imputation = np.abs(stats.zscore(df[['MSSubClass']]))\n","\n","# Identify outliers after imputation\n","outliers_after = (z_scores_post_imputation > threshold).sum(axis=0)\n","\n","# Print out the number of outliers before and after imputation\n","print(f\"Outliers before imputation: {df['MSSubClass']}\")\n","print(f\"Outliers after imputation: {outliers_after}\")\n","\n","#***********************OUTLIERS***************************************************************\n","\n","#************************MISSING VALUES******************************************\n","missing_values = df.isnull().sum()\n","# Instead of dropping rows with missing values, impute with most frequent value\n","for column in df.columns:\n","    if df[column].dtype == 'object':  # Check if column is categorical\n","        df[column] = df[column].fillna(df[column].mode()[0]) # Fill missing values with mode\n","    else:\n","        df[column] = df[column].fillna(df[column].mean()) # Fill missing values with mean\n","#Save the Cleaned Dataset\n","df.to_csv(\"cleaned.csv\")\n","#**************************MISSING VALUES ***********************************************"]},{"cell_type":"markdown","source":["Outliers"],"metadata":{"id":"T-OmERVkMS4m"}},{"cell_type":"code","source":["import pandas as pd\n","from scipy import stats\n","import numpy as np\n","\n","# Load your dataset\n","df = pd.read_csv('train.csv')\n","#*********OUTLIERS*********************\n","# Select only the numerical columns\n","numerical_df = df.select_dtypes(include=[np.number])\n","\n","# Calculate the Z-scores for each numerical column\n","z_scores = np.abs(stats.zscore(numerical_df))\n","\n","# Set a threshold for identifying outliers\n","threshold = 3\n","\n","# Assuming you want to replace outliers based on z-score\n","# and replace them with median for the column\n","upper_limit = numerical_df['MSSubClass'].mean() + threshold * numerical_df['MSSubClass'].std()\n","median = numerical_df['MSSubClass'].median()\n","df['MSSubClass'] = df['MSSubClass'].apply(lambda x: median if x > upper_limit else x)\n","\n","\n","print(df['MSSubClass'])\n","#***********************OUTLIERS************************"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"Oprp53YMMWTH","executionInfo":{"status":"ok","timestamp":1731632450673,"user_tz":-600,"elapsed":583,"user":{"displayName":"Ned Palom","userId":"06455553497609884633"}},"outputId":"ca8d24a8-97ee-46fa-d725-d1b87937fc9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0       60.0\n","1       20.0\n","2       60.0\n","3       70.0\n","4       60.0\n","        ... \n","1455    60.0\n","1456    20.0\n","1457    70.0\n","1458    20.0\n","1459    20.0\n","Name: MSSubClass, Length: 1460, dtype: float64\n"]}]},{"cell_type":"markdown","source":["Encode Train Data"],"metadata":{"id":"PSdxL-Q5tar3"}},{"cell_type":"code","source":["from re import X\n","#Import Necessary Libraries\n","\n","from sklearn.preprocessing import OneHotEncoder\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","#Load cleaned dataset\n","train_encode = pd.read_csv('cleaned.csv')\n","train_encode = pd.DataFrame(train_encode)\n","\n","#Find non-numerical values in the cleaned dataset\n","def find_non_numerical(train_encode):\n","    non_numerical = []\n","    for column in df.columns:\n","        if df[column].dtype == 'object':\n","            non_numerical.append(column)\n","    return non_numerical\n","#print(find_non_numerical(train_encode))\n","\n","#Separate features and Target\n","X = train_encode[find_non_numerical(train_encode)]\n","y = train_encode['SalePrice']\n","\n","#Initialize OneHotEncoder\n","encoder = OneHotEncoder(sparse_output=False, drop='first')\n","\n","#Fit and Transform the Features\n","X_encoded = encoder.fit_transform(X)\n","\n","#Convert to dataframes and column names\n","encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n","\n","df_encoded = pd.concat([encoded_df, y], axis=1)\n","#print(df_encoded)\n","\n","#Save the Encoded Dataset\n","df_encoded.to_csv(\"encoded.csv\")"],"metadata":{"collapsed":true,"id":"EI8pdyf8ua3G","executionInfo":{"status":"ok","timestamp":1731715954337,"user_tz":-600,"elapsed":947,"user":{"displayName":"Ned Palom","userId":"06455553497609884633"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Model Training"],"metadata":{"id":"lWOkEBft3yqS"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import joblib\n","\n","#Load and prepare dataset\n","data = pd.read_csv('encoded.csv')\n","\n","#Specify the name of the target column\n","target_column = 'SalePrice'\n","\n","#Separate features and target\n","X = data.drop(columns=[target_column])\n","y = data[target_column]\n","\n","# Initialize the Random Forest model\n","#rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","\n","#Initialize the model here\n","rf_model = GradientBoostingRegressor()\n","\n","#Fit the model with the entire dataset\n","rf_model.fit(X, y)\n","\n","#Make predictions on the same dataset since we are not splitting\n","y_pred = rf_model.predict(X)\n","\n","# Evaluate the model using regression metrics\n","# Calculate Mean Squared Error (MSE)\n","mse = mean_squared_error(y, y_pred)\n","# Calculate R-squared (R2)\n","r2 = r2_score(y, y_pred)\n","\n","# Print the evaluation metrics\n","print(f\"Mean Squared Error (MSE): {mse}\")\n","print(f\"R-squared (R2): {r2}\")\n","\n","# Save the trained model\n","joblib.dump(rf_model, 'model_1')\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"WbkTsb5V39Je","executionInfo":{"status":"ok","timestamp":1731715959357,"user_tz":-600,"elapsed":2005,"user":{"displayName":"Ned Palom","userId":"06455553497609884633"}},"outputId":"dad5e3d7-6b86-4c74-cb18-344a62a21f3f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error (MSE): 771040092.7065036\n","R-squared (R2): 0.877744420591863\n"]},{"output_type":"execute_result","data":{"text/plain":["['model_1']"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Clean Test Dataset"],"metadata":{"id":"RasnL1DJEYm6"}},{"cell_type":"code","source":["import pandas as pd\n","\n","#identify missing values\n","df = pd.read_csv('test.csv')\n","missing_values = df.isnull().sum()\n","# Instead of dropping rows with missing values, impute with most frequent value\n","for column in df.columns:\n","    if df[column].dtype == 'object':  # Check if column is categorical\n","        df[column] = df[column].fillna(df[column].mode()[0]) # Fill missing values with mode\n","    else:\n","        df[column] = df[column].fillna(df[column].mean()) # Fill missing values with mean\n","#Save the Cleaned Dataset\n","df.to_csv(\"cleaned_test.csv\")"],"metadata":{"id":"Sna69VjOEc4L","executionInfo":{"status":"ok","timestamp":1731715964398,"user_tz":-600,"elapsed":633,"user":{"displayName":"Ned Palom","userId":"06455553497609884633"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Encode Test Dataset"],"metadata":{"id":"L41ICV_KEAFX"}},{"cell_type":"code","source":["from re import X\n","#Import Necessary Libraries\n","from sklearn.preprocessing import OneHotEncoder\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","#Load cleaned dataset\n","test_encode = pd.read_csv('cleaned_test.csv')\n","test_encode = pd.DataFrame(test_encode)\n","\n","#Find non-numerical values in the cleaned dataset\n","def find_non_numerical(test_encode):\n","    non_numerical = []\n","    for column in df.columns:\n","        if df[column].dtype == 'object':\n","            non_numerical.append(column)\n","    return non_numerical\n","#print(find_non_numerical(train_encode))\n","\n","#Separate features and Target\n","X = test_encode[find_non_numerical(test_encode)]\n","y = test_encode['Id']\n","\n","#Initialize OneHotEncoder\n","encoder = OneHotEncoder(sparse_output=False, drop='first')\n","\n","#Fit and Transform the Features\n","X_encoded = encoder.fit_transform(X)\n","\n","#Convert to dataframes and column names\n","encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(X.columns))\n","\n","df_encoded = pd.concat([encoded_df, y], axis=1)\n","#print(df_encoded)\n","\n","#Save the Encoded Dataset\n","df_encoded.to_csv(\"encoded_test.csv\")"],"metadata":{"id":"rLnedjblEDom","executionInfo":{"status":"ok","timestamp":1731715966189,"user_tz":-600,"elapsed":527,"user":{"displayName":"Ned Palom","userId":"06455553497609884633"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Predict Housing Price"],"metadata":{"id":"1lvTZ5wAXvwu"}},{"cell_type":"code","source":["import pandas as pd\n","import joblib\n","\n","# Load the model\n","model = joblib.load('model_1')\n","\n","# Load the training data to get the original feature names\n","predict_data = pd.read_csv('encoded.csv')  # Replace with the path to your encoded training data\n","predict_features = predict_data.drop(columns=['SalePrice']).columns  # Get the feature names from the training data\n","\n","# Load the test data\n","test_data = pd.read_csv('encoded_test.csv')\n","\n","# Specify the name of the target column (if it exists in test data, remove it)\n","target_column = 'Id'  # Replace with your actual target column name, if needed\n","\n","# **Store 'Id' before reindexing**\n","index_ids = test_data['Id'].tolist()\n","\n","# Remove the target column if it exists in test data\n","if target_column in test_data.columns:\n","    test_data = test_data.drop(columns=[target_column])\n","\n","# Reindex the test data to match the training data columns\n","test_data = test_data.reindex(columns=predict_features, fill_value=0) # Fill missing values with 0\n","\n","# Make predictions for each row in the test data\n","predictions = model.predict(test_data)\n","\n","# Create a DataFrame with Item_Identifier and Item_Outlet_Sales columns\n","results = pd.DataFrame({\n","    'Id': index_ids,\n","    'SalePrice': predictions\n","})\n","\n","# Display the results\n","print(results)\n","\n","# Optionally, save the results to a CSV file\n","results.to_csv('HousingPricePrediction2.csv', index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"NXw9R4McBjsg","executionInfo":{"status":"ok","timestamp":1731715971611,"user_tz":-600,"elapsed":486,"user":{"displayName":"Ned Palom","userId":"06455553497609884633"}},"outputId":"38d3ef11-bcac-4791-a5e0-a72b4efcf7a9"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["        Id      SalePrice\n","0     1461  164405.011509\n","1     1462  189471.970586\n","2     1463  248311.109665\n","3     1464  237643.124412\n","4     1465  260052.520477\n","...    ...            ...\n","1454  2915  154696.719373\n","1455  2916  164693.264048\n","1456  2917  200418.812150\n","1457  2918  224562.009428\n","1458  2919  322335.584551\n","\n","[1459 rows x 2 columns]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wo2k2hIAOWze"},"execution_count":null,"outputs":[]}]}